{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "word-embeddings-and-similarity.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMCk2N82riy67hLvCb0rHG4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahul1990gupta/indic-nlp-datasets/blob/master/examples/word_embeddings_and_similarity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxOXbW5jso37",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from spacy.lang.hi import Hindi \n",
        "nlp = Hindi()\n",
        "sent1 = 'मुझे भोजन पसंद है।'\n",
        "doc = nlp(sent1)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfyuK9p_tORv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "15bcdcea-ef1b-4b88-9efe-3466a73ab28e"
      },
      "source": [
        "doc[0].vector"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l07SMJKatoD4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# As we can see that there are no word embeddings available for hindi words. \n",
        "# Luckily, there are word embeddings available online under fasttext project by facebook\n",
        "# So, we will download them and load that in spaCy\n",
        "import requests \n",
        "url = \"https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.hi.300.vec.gz\"\n",
        "r = requests.get(url, allow_redirects=True)\n",
        "fpath = url.split(\"/\")[-1]\n",
        "with open(fpath, \"wb\") as fw:\n",
        "  fw.write(r.content)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4JkYzFtwjL6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "outputId": "853cd6d1-a760-4177-c84d-c3bbfda9c2a4"
      },
      "source": [
        "# The file is about 1 GB in size. So, it will take some time to download. \n",
        "# Let's see how we can use external word embeddings in spaCy\n",
        "# Here is a link to spacy documentation on how to do this https://spacy.io/usage/vectors-similarity#converting\n",
        "\n",
        "! python -m spacy init-model hi ./hi_vectors_wiki_lg --vectors-loc cc.hi.300.vec.gz\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r⠙ Creating model...\r\u001b[2K\u001b[38;5;2m✔ Successfully created model\u001b[0m\n",
            "⠙ Reading vectors from cc.hi.300.vec.gztcmalloc: large alloc 2251988992 bytes == 0x2dac000 @  0x7f6b1fca8001 0x7f6b1d80c765 0x7f6b1d870bb0 0x7f6b1d872a4f 0x7f6b1d909048 0x50a7f5 0x50cfd6 0x509918 0x50a64d 0x50c1f4 0x507f24 0x509c50 0x50a64d 0x50c1f4 0x507f24 0x588e91 0x59fe1e 0x50d596 0x507f24 0x509c50 0x50a64d 0x50c1f4 0x507f24 0x509c50 0x50a64d 0x50c1f4 0x507f24 0x5165a5 0x50a47f 0x50c1f4 0x507f24\n",
            "1876653it [02:55, 10704.01it/s]\n",
            "\u001b[2K\u001b[38;5;2m✔ Loaded vectors from cc.hi.300.vec.gz\u001b[0m\n",
            "\u001b[38;5;2m✔ Sucessfully compiled vocab\u001b[0m\n",
            "1876653 entries, 1876653 vectors\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urinN9K1x3ut",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ce9cd2e3-add5-4b9a-cd3d-9df1b52d5c8f"
      },
      "source": [
        "# Let's load the model now in spacy to do some work\n",
        "import spacy\n",
        "nlp_hi = spacy.load(\"./hi_vectors_wiki_lg\")\n",
        "doc = nlp_hi(sent1)\n",
        "doc[0].vector"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 5.210e-02, -4.990e-02,  9.150e-02, -8.800e-03,  7.370e-02,\n",
              "       -4.700e-03, -3.410e-02,  4.200e-03,  2.160e-02,  2.810e-02,\n",
              "       -5.430e-02, -2.680e-02,  2.070e-02, -1.120e-02,  3.960e-02,\n",
              "       -1.140e-02,  1.108e-01,  1.560e-02, -2.690e-02,  1.336e-01,\n",
              "       -1.290e-02,  6.110e-02, -1.520e-02, -5.390e-02, -3.870e-02,\n",
              "        2.180e-02, -4.010e-02, -4.380e-02,  4.030e-02,  6.700e-03,\n",
              "       -6.400e-03, -2.020e-02,  3.660e-02, -4.700e-03,  6.030e-02,\n",
              "        6.860e-02,  1.070e-02, -8.210e-02, -3.090e-02,  1.620e-02,\n",
              "       -2.700e-03,  4.910e-02, -2.800e-03, -3.250e-02,  1.030e-02,\n",
              "        9.310e-02, -1.380e-02, -6.380e-02, -1.900e-02, -3.220e-02,\n",
              "       -9.700e-03, -5.200e-03, -7.400e-03,  9.890e-02, -1.530e-02,\n",
              "       -4.380e-02,  1.590e-02,  8.700e-03, -9.600e-03, -1.080e-02,\n",
              "       -3.300e-03, -2.090e-02, -7.560e-02,  6.220e-02,  3.440e-02,\n",
              "       -5.700e-03, -7.590e-02, -5.490e-02, -9.000e-04, -4.920e-02,\n",
              "        4.610e-02, -5.360e-02,  2.080e-02,  7.690e-02,  4.200e-03,\n",
              "        7.270e-02,  9.700e-03,  2.490e-02, -1.800e-02,  1.460e-02,\n",
              "       -8.320e-02, -4.090e-02, -4.590e-02,  4.800e-03,  1.600e-03,\n",
              "       -4.400e-03, -4.030e-02, -2.160e-02,  2.480e-02, -2.207e-01,\n",
              "        3.500e-02, -6.000e-03,  2.130e-02,  2.550e-02,  1.870e-02,\n",
              "       -4.900e-02, -2.860e-02,  6.260e-02,  3.200e-03, -2.520e-02,\n",
              "       -5.800e-03,  2.710e-02, -2.630e-02, -2.600e-03, -4.200e-02,\n",
              "        4.430e-02, -4.850e-02,  1.410e-02,  4.700e-03,  8.800e-03,\n",
              "       -3.270e-02,  1.410e-02, -3.980e-02, -1.320e-02, -4.620e-02,\n",
              "        1.430e-02, -3.760e-02,  1.610e-02,  5.750e-02,  6.000e-03,\n",
              "       -5.770e-02,  3.100e-03,  5.500e-03,  2.440e-02,  6.600e-03,\n",
              "        5.710e-02,  5.590e-02,  5.760e-02,  2.740e-02,  4.150e-02,\n",
              "        1.140e-02,  1.630e-02,  3.520e-02,  3.960e-02,  9.410e-02,\n",
              "       -6.720e-02,  4.960e-02, -1.970e-02,  1.740e-02,  7.010e-02,\n",
              "        5.610e-02,  2.090e-02, -7.270e-02, -2.570e-02,  4.100e-03,\n",
              "        9.500e-03, -5.500e-03, -1.360e-02,  2.000e-03, -1.990e-02,\n",
              "        8.220e-02,  6.780e-02, -5.860e-02,  7.000e-04, -2.210e-02,\n",
              "        7.330e-02,  5.600e-03, -2.200e-03, -6.400e-02,  7.400e-02,\n",
              "       -1.160e-02,  1.660e-02, -3.570e-02, -3.380e-02, -1.330e-02,\n",
              "       -5.840e-02,  1.500e-02, -2.260e-02, -5.620e-02,  8.660e-02,\n",
              "        3.460e-02,  2.860e-02, -5.270e-02, -4.840e-02, -7.140e-02,\n",
              "        6.970e-02,  2.950e-02,  1.340e-02, -2.160e-02,  1.060e-02,\n",
              "        5.800e-02,  1.136e-01,  3.000e-04, -1.490e-02,  2.420e-02,\n",
              "        5.380e-02, -2.720e-02,  2.800e-02, -1.050e-02, -1.870e-02,\n",
              "       -7.120e-02,  1.200e-03, -7.810e-02,  5.180e-02, -4.900e-03,\n",
              "        8.700e-03, -6.700e-03,  6.300e-03, -1.440e-02, -3.500e-03,\n",
              "       -9.950e-02, -7.000e-03,  4.540e-02, -8.900e-03,  2.000e-03,\n",
              "       -1.019e-01, -9.900e-03, -3.780e-02,  1.220e-01, -1.000e-04,\n",
              "        1.750e-02,  3.290e-02,  2.420e-02, -7.200e-03, -1.950e-02,\n",
              "       -2.080e-02,  1.480e-02,  1.020e-01,  2.250e-02,  6.010e-02,\n",
              "        2.760e-02, -1.250e-02,  8.800e-03, -9.120e-02,  1.800e-02,\n",
              "       -3.700e-02, -3.210e-02,  7.500e-03, -4.440e-02, -7.020e-02,\n",
              "       -5.160e-02,  2.760e-02, -7.200e-03, -1.770e-02, -1.490e-02,\n",
              "        2.930e-02, -1.410e-02, -2.930e-02, -4.580e-02, -3.560e-02,\n",
              "       -5.560e-02,  2.500e-02,  1.920e-02, -1.740e-02, -4.880e-02,\n",
              "       -5.420e-02,  1.540e-02, -1.600e-03,  2.800e-03, -5.400e-02,\n",
              "       -4.090e-02,  2.760e-02, -3.530e-02,  7.600e-03,  2.350e-02,\n",
              "        1.820e-02, -2.850e-02, -1.240e-02,  6.000e-02, -1.260e-02,\n",
              "       -2.900e-03, -1.400e-02, -9.500e-03, -2.300e-02, -7.700e-03,\n",
              "       -7.840e-02, -1.570e-02, -3.220e-02, -8.370e-02,  7.370e-02,\n",
              "        3.320e-02,  1.570e-02, -7.370e-02, -2.370e-02,  8.370e-02,\n",
              "        9.600e-03, -9.400e-03, -5.930e-02,  5.150e-02, -1.600e-02,\n",
              "        3.080e-02, -6.000e-03, -1.860e-02,  4.430e-02,  3.310e-02,\n",
              "       -8.100e-03, -3.300e-03, -6.910e-02,  2.400e-02, -1.360e-02,\n",
              "        4.110e-02,  7.600e-03, -2.240e-02, -9.050e-02,  2.510e-02,\n",
              "       -2.810e-02, -1.480e-02, -4.000e-03,  2.290e-02, -2.550e-02],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9Lveq4TybBk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b795b675-858f-457e-9f70-58fead5b6510"
      },
      "source": [
        "# Looks like vectors are loaded. \n",
        "# Let's use these vectors to compare two very similar sentences\n",
        "\n",
        "sent2 = 'मैं ऐसे भोजन की सराहना करता हूं जिसका स्वाद अच्छा हो।'\n",
        "doc1 = nlp_hi(sent1)\n",
        "doc2 = nlp_hi(sent2)\n",
        "\n",
        "# Both the sent1 and sent2 are very similar, so, we expect their similarity score to be high\n",
        "doc1.similarity(doc2)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8630901600736095"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoNvdyXEzSeq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "15509334-c603-4381-e47e-497f56aa36ca"
      },
      "source": [
        "# similarity score implied that both the sentences are very similar\n",
        "# Now, Let's find synonyms for a word using word embeddings \n",
        "doc1[1]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "भोजन"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwosNLm_01f-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "outputId": "d32794e1-cc36-4b02-a46e-c43b0f39b3cf"
      },
      "source": [
        "vector1 = doc1[1].vector\n",
        "result = nlp_hi.vocab.vectors.most_similar(vector1.transpose())\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AxisError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-00b9473a691b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mvector1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp_hi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32mvectors.pyx\u001b[0m in \u001b[0;36mspacy.vectors.Vectors.most_similar\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mnorm\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36mnorm\u001b[0;34m(x, ord, axis, keepdims)\u001b[0m\n\u001b[1;32m   2505\u001b[0m             \u001b[0;31m# special case for speedup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2506\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2507\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2508\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2509\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hphn5zTS2hGO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Uh-oh. Something is not right. Let's go to github issues\n",
        "# Somebody suggested here to reshape the vector https://github.com/explosion/spaCy/issues/276\n",
        "# Let's do that \n",
        "def get_similar_words(word):\n",
        "  vector = word.vector\n",
        "  results = nlp_hi.vocab.vectors.most_similar(vector.reshape(1, 300))\n",
        "\n",
        "  ret = []\n",
        "  for result in results:    \n",
        "    try:\n",
        "      candidate = nlp_hi.vocab[result[0][0]]\n",
        "      ret.append(candidate.text)\n",
        "    except KeyError:\n",
        "      pass\n",
        "    return ret\n",
        "\n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrWAxgzA3jwR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f43bdac2-8666-406c-dc39-2d33b3b371ac"
      },
      "source": [
        "get_similar_words(doc[1])"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['भोजन']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YM1SDPgW3mui",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "0d6e39ae-14c3-4020-d6d9-bdcbdf935c22"
      },
      "source": [
        "# That's not useful. Let's try some other words \n",
        "words = \"सुंदर दिन माँ भाई\"\n",
        "doc = nlp_hi(words)\n",
        "\n",
        "for token in doc:\n",
        "  print(nlp_hi.vocab.vectors.most_similar(token.vector.reshape(1, 300)))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(array([[3568482901620635625]], dtype=uint64), array([[1220]], dtype=int32), array([[1.]], dtype=float32))\n",
            "(array([[5776141810202350524]], dtype=uint64), array([[137]], dtype=int32), array([[1.]], dtype=float32))\n",
            "(array([[13757753178649016088]], dtype=uint64), array([[559]], dtype=int32), array([[1.]], dtype=float32))\n",
            "(array([[14413965628861974583]], dtype=uint64), array([[485]], dtype=int32), array([[1.]], dtype=float32))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8jCKCrX4i6z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hmm. seems like there is something wrong with wither spacy or word vectors. Maybe word vectors are very sparse and trained on very little \n",
        "# data \n",
        "\n",
        "# There is a nltk library for looking up similarity. Next time we will try that.  \n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}